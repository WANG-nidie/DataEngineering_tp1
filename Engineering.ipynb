{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>-1</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>-1</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>-1</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>-1</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  sentiment  \\\n",
       "0      570306133677760513          0   \n",
       "1      570301130888122368          1   \n",
       "2      570301083672813571          0   \n",
       "3      570301031407624196         -1   \n",
       "4      570300817074462722         -1   \n",
       "...                   ...        ...   \n",
       "14635  569587686496825344          1   \n",
       "14636  569587371693355008         -1   \n",
       "14637  569587242672398336          0   \n",
       "14638  569587188687634433         -1   \n",
       "14639  569587140490866689          0   \n",
       "\n",
       "                                                  review  \n",
       "0                    @VirginAmerica What @dhepburn said.  \n",
       "1      @VirginAmerica plus you've added commercials t...  \n",
       "2      @VirginAmerica I didn't today... Must mean I n...  \n",
       "3      @VirginAmerica it's really aggressive to blast...  \n",
       "4      @VirginAmerica and it's a really big bad thing...  \n",
       "...                                                  ...  \n",
       "14635  @AmericanAir thank you we got on a different f...  \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...  \n",
       "14637  @AmericanAir Please bring American Airlines to...  \n",
       "14638  @AmericanAir you have my money, you change my ...  \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...  \n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "import re #regular expressions\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/Lenovo/Desktop/Tweets.csv\")\n",
    "data = df[['id','sentiment','review']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[0:int(len(data)*0.8)]             #divide into 8:2\n",
    "test = data.iloc[int(len(data)*0.8):int(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_wordlist(review, remove_stopwords=False):# preprocessing\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))     \n",
    "        words = [w for w in words if not w in stops]\n",
    "    return(words)\n",
    "\n",
    "def review_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence)>0:\n",
    "            sentences.append(review_wordlist(raw_sentence,\\\n",
    "                                            remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-11 17:54:45,748 : INFO : collecting all words and their counts\n",
      "2020-11-11 17:54:45,750 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-11-11 17:54:45,783 : INFO : PROGRESS: at sentence #10000, processed 90036 words, keeping 7471 word types\n",
      "2020-11-11 17:54:45,809 : INFO : PROGRESS: at sentence #20000, processed 176419 words, keeping 11406 word types\n",
      "2020-11-11 17:54:45,819 : INFO : collected 12324 word types from a corpus of 208395 raw words and 23504 sentences\n",
      "2020-11-11 17:54:45,822 : INFO : Loading a fresh vocabulary\n",
      "2020-11-11 17:54:45,830 : INFO : effective_min_count=40 retains 619 unique words (5% of original 12324, drops 11705)\n",
      "2020-11-11 17:54:45,831 : INFO : effective_min_count=40 leaves 168481 word corpus (80% of original 208395, drops 39914)\n",
      "2020-11-11 17:54:45,836 : INFO : deleting the raw counts dictionary of 12324 items\n",
      "2020-11-11 17:54:45,837 : INFO : sample=0.001 downsamples 76 most-common words\n",
      "2020-11-11 17:54:45,838 : INFO : downsampling leaves estimated 109601 word corpus (65.1% of prior 168481)\n",
      "2020-11-11 17:54:45,841 : INFO : estimated required memory for 619 words and 300 dimensions: 1795100 bytes\n",
      "2020-11-11 17:54:45,842 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-11 17:54:45,962 : INFO : training model with 4 workers on 619 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-11-11 17:54:46,076 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-11 17:54:46,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-11 17:54:46,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-11 17:54:46,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-11 17:54:46,088 : INFO : EPOCH - 1 : training on 208395 raw words (109174 effective words) took 0.1s, 1114839 effective words/s\n",
      "2020-11-11 17:54:46,183 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-11 17:54:46,187 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-11 17:54:46,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-11 17:54:46,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-11 17:54:46,191 : INFO : EPOCH - 2 : training on 208395 raw words (109519 effective words) took 0.1s, 1221163 effective words/s\n",
      "2020-11-11 17:54:46,289 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-11 17:54:46,290 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-11 17:54:46,293 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-11 17:54:46,295 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-11 17:54:46,296 : INFO : EPOCH - 3 : training on 208395 raw words (109434 effective words) took 0.1s, 1220853 effective words/s\n",
      "2020-11-11 17:54:46,389 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-11 17:54:46,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-11 17:54:46,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-11 17:54:46,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-11 17:54:46,398 : INFO : EPOCH - 4 : training on 208395 raw words (109671 effective words) took 0.1s, 1222676 effective words/s\n",
      "2020-11-11 17:54:46,500 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-11 17:54:46,501 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-11 17:54:46,504 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-11 17:54:46,508 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-11 17:54:46,510 : INFO : EPOCH - 5 : training on 208395 raw words (109613 effective words) took 0.1s, 1116379 effective words/s\n",
      "2020-11-11 17:54:46,510 : INFO : training on a 1041975 raw words (547411 effective words) took 0.5s, 999095 effective words/s\n",
      "2020-11-11 17:54:46,513 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-11-11 17:54:46,518 : INFO : saving Word2Vec object under Model, separately None\n",
      "2020-11-11 17:54:46,520 : INFO : not storing attribute vectors_norm\n",
      "2020-11-11 17:54:46,521 : INFO : not storing attribute cum_table\n",
      "2020-11-11 17:54:46,542 : INFO : saved Model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "num_features = 300  \n",
    "min_word_count = 40 \n",
    "num_workers = 4     \n",
    "context = 10        \n",
    "downsampling = 1e-3 \n",
    "\n",
    "print(\"Training model....\")\n",
    "model = word2vec.Word2Vec(sentences,\\\n",
    "                          workers=num_workers,\\\n",
    "                          size=num_features,\\\n",
    "                          min_count=min_word_count,\\\n",
    "                          window=context,\n",
    "                          sample=downsampling)\n",
    "\n",
    "model.init_sims(replace=True) #é«˜æ•ˆ\n",
    "model.save(\"C:/Users/Lenovo/Desktop/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureVecMethod(words, model, num_features):\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0   \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))      \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 11712\n",
      "Review 1000 of 11712\n",
      "Review 2000 of 11712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-3be60fb87c9f>:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec,model[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 3000 of 11712\n",
      "Review 4000 of 11712\n",
      "Review 5000 of 11712\n",
      "Review 6000 of 11712\n",
      "Review 7000 of 11712\n",
      "Review 8000 of 11712\n",
      "Review 9000 of 11712\n",
      "Review 10000 of 11712\n",
      "Review 11000 of 11712\n"
     ]
    }
   ],
   "source": [
    "#model = word2vec.load(\"C:/Users/Lenovo/Desktop/model\")\n",
    "\n",
    "train_reviews = []\n",
    "for review in train['review']:\n",
    "    train_reviews.append(review_wordlist(review, remove_stopwords=True))\n",
    "trainDataVecs = getAvgFeatureVecs(train_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 2928\n",
      "Review 1000 of 2928\n",
      "Review 2000 of 2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-3be60fb87c9f>:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec,model[word])\n"
     ]
    }
   ],
   "source": [
    "test_reviews = []\n",
    "\n",
    "for review in test['review']:\n",
    "    test_reviews.append(review_wordlist(review, remove_stopwords=True))\n",
    "testDataVecs = getAvgFeatureVecs(test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7435109289617486"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "RFmodel = RandomForestClassifier(n_estimators = 100)\n",
    "RFmodel = forest.fit(trainDataVecs,train[\"sentiment\"])\n",
    "#with open('C:/Users/Lenovo/Desktop/RFmodel.pickle', 'wb') as file:\n",
    "#    pickle.dump(forest, file)\n",
    "\n",
    "result = RFmodel.predict(testDataVecs)\n",
    "answer = []\n",
    "for i in range(0, len(test)):\n",
    "    answer.append(test.iloc[i]['sentiment'])\n",
    "acc = sum(answer == result)/len(result)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
