{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading popular: <urlopen error [WinError 10054]\n",
      "[nltk_data]     远程主机强迫关闭了一个现有的连接。>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "import re #regular expressions\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/Lenovo/Desktop/labeledTrainData.tsv\", header=0,\\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(\"C:/Users/Lenovo/Desktop/testData.tsv\",header=0,\\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_wordlist(review, remove_stopwords=False):# preprocessing\n",
    "    \n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))     \n",
    "        words = [w for w in words if not w in stops]\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence)>0:\n",
    "            sentences.append(review_wordlist(raw_sentence,\\\n",
    "                                            remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\bs4\\__init__.py:414: MarkupResemblesLocatorWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-10 15:12:45,868 : INFO : collecting all words and their counts\n",
      "2020-11-10 15:12:45,873 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-10 15:12:46,276 : INFO : PROGRESS: at sentence #10000, processed 224958 words, keeping 17776 word types\n",
      "2020-11-10 15:12:46,475 : INFO : PROGRESS: at sentence #20000, processed 447771 words, keeping 24856 word types\n",
      "2020-11-10 15:12:46,604 : INFO : PROGRESS: at sentence #30000, processed 669436 words, keeping 30088 word types\n",
      "2020-11-10 15:12:46,723 : INFO : PROGRESS: at sentence #40000, processed 896563 words, keeping 34393 word types\n",
      "2020-11-10 15:12:46,840 : INFO : PROGRESS: at sentence #50000, processed 1116307 words, keeping 37828 word types\n",
      "2020-11-10 15:12:46,950 : INFO : PROGRESS: at sentence #60000, processed 1334972 words, keeping 40682 word types\n",
      "2020-11-10 15:12:47,065 : INFO : PROGRESS: at sentence #70000, processed 1558627 words, keeping 43374 word types\n",
      "2020-11-10 15:12:47,193 : INFO : PROGRESS: at sentence #80000, processed 1782139 words, keeping 45791 word types\n",
      "2020-11-10 15:12:47,310 : INFO : PROGRESS: at sentence #90000, processed 2000978 words, keeping 48217 word types\n",
      "2020-11-10 15:12:47,419 : INFO : PROGRESS: at sentence #100000, processed 2223914 words, keeping 50151 word types\n",
      "2020-11-10 15:12:47,525 : INFO : PROGRESS: at sentence #110000, processed 2442794 words, keeping 52103 word types\n",
      "2020-11-10 15:12:47,634 : INFO : PROGRESS: at sentence #120000, processed 2669018 words, keeping 54174 word types\n",
      "2020-11-10 15:12:47,743 : INFO : PROGRESS: at sentence #130000, processed 2886465 words, keeping 55781 word types\n",
      "2020-11-10 15:12:47,868 : INFO : PROGRESS: at sentence #140000, processed 3108967 words, keeping 57470 word types\n",
      "2020-11-10 15:12:47,988 : INFO : PROGRESS: at sentence #150000, processed 3329371 words, keeping 59067 word types\n",
      "2020-11-10 15:12:48,101 : INFO : PROGRESS: at sentence #160000, processed 3552950 words, keeping 60601 word types\n",
      "2020-11-10 15:12:48,209 : INFO : PROGRESS: at sentence #170000, processed 3774816 words, keeping 62084 word types\n",
      "2020-11-10 15:12:48,317 : INFO : PROGRESS: at sentence #180000, processed 3998935 words, keeping 63461 word types\n",
      "2020-11-10 15:12:48,436 : INFO : PROGRESS: at sentence #190000, processed 4222059 words, keeping 64790 word types\n",
      "2020-11-10 15:12:48,563 : INFO : PROGRESS: at sentence #200000, processed 4444838 words, keeping 66067 word types\n",
      "2020-11-10 15:12:48,707 : INFO : PROGRESS: at sentence #210000, processed 4668997 words, keeping 67396 word types\n",
      "2020-11-10 15:12:48,839 : INFO : PROGRESS: at sentence #220000, processed 4892989 words, keeping 68743 word types\n",
      "2020-11-10 15:12:48,970 : INFO : PROGRESS: at sentence #230000, processed 5119437 words, keeping 69966 word types\n",
      "2020-11-10 15:12:49,111 : INFO : PROGRESS: at sentence #240000, processed 5339934 words, keeping 71202 word types\n",
      "2020-11-10 15:12:49,246 : INFO : PROGRESS: at sentence #250000, processed 5554076 words, keeping 72366 word types\n",
      "2020-11-10 15:12:49,380 : INFO : PROGRESS: at sentence #260000, processed 5775126 words, keeping 73479 word types\n",
      "2020-11-10 15:12:49,399 : INFO : collected 73643 word types from a corpus of 5804934 raw words and 261327 sentences\n",
      "2020-11-10 15:12:49,401 : INFO : Loading a fresh vocabulary\n",
      "2020-11-10 15:12:49,501 : INFO : effective_min_count=40 retains 8194 unique words (11% of original 73643, drops 65449)\n",
      "2020-11-10 15:12:49,503 : INFO : effective_min_count=40 leaves 5446906 word corpus (93% of original 5804934, drops 358028)\n",
      "2020-11-10 15:12:49,556 : INFO : deleting the raw counts dictionary of 73643 items\n",
      "2020-11-10 15:12:49,560 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2020-11-10 15:12:49,561 : INFO : downsampling leaves estimated 3960425 word corpus (72.7% of prior 5446906)\n",
      "2020-11-10 15:12:49,612 : INFO : estimated required memory for 8194 words and 300 dimensions: 23762600 bytes\n",
      "2020-11-10 15:12:49,613 : INFO : resetting layer weights\n",
      "2020-11-10 15:12:52,096 : INFO : training model with 4 workers on 8194 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-11-10 15:12:53,135 : INFO : EPOCH 1 - PROGRESS: at 14.62% examples, 579936 words/s, in_qsize 8, out_qsize 0\n",
      "2020-11-10 15:12:54,151 : INFO : EPOCH 1 - PROGRESS: at 28.50% examples, 558090 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:12:55,155 : INFO : EPOCH 1 - PROGRESS: at 42.63% examples, 557462 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:12:56,171 : INFO : EPOCH 1 - PROGRESS: at 57.47% examples, 562328 words/s, in_qsize 8, out_qsize 0\n",
      "2020-11-10 15:12:57,177 : INFO : EPOCH 1 - PROGRESS: at 71.31% examples, 559663 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:12:58,180 : INFO : EPOCH 1 - PROGRESS: at 85.83% examples, 562406 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:12:59,070 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-10 15:12:59,072 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-10 15:12:59,074 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-10 15:12:59,075 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-10 15:12:59,077 : INFO : EPOCH - 1 : training on 5804934 raw words (3960183 effective words) took 7.0s, 569798 effective words/s\n",
      "2020-11-10 15:13:00,103 : INFO : EPOCH 2 - PROGRESS: at 14.28% examples, 566864 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:01,108 : INFO : EPOCH 2 - PROGRESS: at 28.49% examples, 561222 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:02,111 : INFO : EPOCH 2 - PROGRESS: at 42.81% examples, 562300 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:03,124 : INFO : EPOCH 2 - PROGRESS: at 57.29% examples, 562826 words/s, in_qsize 8, out_qsize 0\n",
      "2020-11-10 15:13:04,146 : INFO : EPOCH 2 - PROGRESS: at 72.68% examples, 570567 words/s, in_qsize 6, out_qsize 1\n",
      "2020-11-10 15:13:05,153 : INFO : EPOCH 2 - PROGRESS: at 86.19% examples, 564415 words/s, in_qsize 8, out_qsize 0\n",
      "2020-11-10 15:13:06,158 : INFO : EPOCH 2 - PROGRESS: at 98.13% examples, 550611 words/s, in_qsize 6, out_qsize 1\n",
      "2020-11-10 15:13:06,254 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-10 15:13:06,266 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-10 15:13:06,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-10 15:13:06,284 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-10 15:13:06,287 : INFO : EPOCH - 2 : training on 5804934 raw words (3961154 effective words) took 7.2s, 550810 effective words/s\n",
      "2020-11-10 15:13:07,330 : INFO : EPOCH 3 - PROGRESS: at 12.28% examples, 478437 words/s, in_qsize 8, out_qsize 0\n",
      "2020-11-10 15:13:08,342 : INFO : EPOCH 3 - PROGRESS: at 24.87% examples, 484406 words/s, in_qsize 8, out_qsize 3\n",
      "2020-11-10 15:13:09,351 : INFO : EPOCH 3 - PROGRESS: at 38.65% examples, 503120 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:10,364 : INFO : EPOCH 3 - PROGRESS: at 51.98% examples, 506800 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:11,369 : INFO : EPOCH 3 - PROGRESS: at 65.53% examples, 512443 words/s, in_qsize 8, out_qsize 1\n",
      "2020-11-10 15:13:12,401 : INFO : EPOCH 3 - PROGRESS: at 80.06% examples, 520676 words/s, in_qsize 6, out_qsize 1\n",
      "2020-11-10 15:13:13,406 : INFO : EPOCH 3 - PROGRESS: at 95.42% examples, 532465 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:13,688 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-10 15:13:13,699 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-10 15:13:13,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-10 15:13:13,712 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-10 15:13:13,716 : INFO : EPOCH - 3 : training on 5804934 raw words (3961551 effective words) took 7.4s, 534637 effective words/s\n",
      "2020-11-10 15:13:14,741 : INFO : EPOCH 4 - PROGRESS: at 14.45% examples, 572832 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:15,747 : INFO : EPOCH 4 - PROGRESS: at 30.19% examples, 594365 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:16,761 : INFO : EPOCH 4 - PROGRESS: at 46.01% examples, 602429 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:17,764 : INFO : EPOCH 4 - PROGRESS: at 61.73% examples, 606140 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:18,767 : INFO : EPOCH 4 - PROGRESS: at 77.17% examples, 607469 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-10 15:13:19,775 : INFO : EPOCH 4 - PROGRESS: at 92.59% examples, 607499 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:20,221 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-10 15:13:20,228 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-10 15:13:20,243 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-10 15:13:20,248 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-10 15:13:20,251 : INFO : EPOCH - 4 : training on 5804934 raw words (3961366 effective words) took 6.5s, 607622 effective words/s\n",
      "2020-11-10 15:13:21,282 : INFO : EPOCH 5 - PROGRESS: at 12.14% examples, 477015 words/s, in_qsize 8, out_qsize 0\n",
      "2020-11-10 15:13:22,283 : INFO : EPOCH 5 - PROGRESS: at 24.87% examples, 489574 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:23,300 : INFO : EPOCH 5 - PROGRESS: at 36.72% examples, 480476 words/s, in_qsize 6, out_qsize 1\n",
      "2020-11-10 15:13:24,304 : INFO : EPOCH 5 - PROGRESS: at 49.04% examples, 480952 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:25,304 : INFO : EPOCH 5 - PROGRESS: at 62.76% examples, 493446 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:26,331 : INFO : EPOCH 5 - PROGRESS: at 77.33% examples, 505565 words/s, in_qsize 8, out_qsize 1\n",
      "2020-11-10 15:13:27,341 : INFO : EPOCH 5 - PROGRESS: at 92.39% examples, 518044 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-10 15:13:27,826 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-10 15:13:27,832 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-10 15:13:27,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-10 15:13:27,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-10 15:13:27,852 : INFO : EPOCH - 5 : training on 5804934 raw words (3961172 effective words) took 7.6s, 522300 effective words/s\n",
      "2020-11-10 15:13:27,855 : INFO : training on a 29024670 raw words (19805426 effective words) took 35.8s, 553870 effective words/s\n",
      "2020-11-10 15:13:27,869 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-11-10 15:13:27,888 : INFO : saving Word2Vec object under Model, separately None\n",
      "2020-11-10 15:13:27,895 : INFO : not storing attribute vectors_norm\n",
      "2020-11-10 15:13:27,897 : INFO : not storing attribute cum_table\n",
      "2020-11-10 15:13:28,190 : INFO : saved Model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "num_features = 300  \n",
    "min_word_count = 40 \n",
    "num_workers = 4     \n",
    "context = 10        \n",
    "downsampling = 1e-3 \n",
    "\n",
    "print(\"Training model....\")\n",
    "model = word2vec.Word2Vec(sentences,\\\n",
    "                          workers=num_workers,\\\n",
    "                          size=num_features,\\\n",
    "                          min_count=min_word_count,\\\n",
    "                          window=context,\n",
    "                          sample=downsampling)\n",
    "\n",
    "model.init_sims(replace=True) #高效\n",
    "\n",
    "# Saving the model for later use. Can be loaded using Word2Vec.load()\n",
    "model_name = \"Model\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureVecMethod(words, model, num_features):\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0   \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))      \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 24500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-cfa758f63ad4>:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec,model[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 24500\n",
      "Review 2000 of 24500\n",
      "Review 3000 of 24500\n",
      "Review 4000 of 24500\n",
      "Review 5000 of 24500\n",
      "Review 6000 of 24500\n",
      "Review 7000 of 24500\n",
      "Review 8000 of 24500\n",
      "Review 9000 of 24500\n",
      "Review 10000 of 24500\n",
      "Review 11000 of 24500\n",
      "Review 12000 of 24500\n",
      "Review 13000 of 24500\n",
      "Review 14000 of 24500\n",
      "Review 15000 of 24500\n",
      "Review 16000 of 24500\n",
      "Review 17000 of 24500\n",
      "Review 18000 of 24500\n",
      "Review 19000 of 24500\n",
      "Review 20000 of 24500\n",
      "Review 21000 of 24500\n",
      "Review 22000 of 24500\n",
      "Review 23000 of 24500\n",
      "Review 24000 of 24500\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "model = Word2Vec.load('300features_40minwords_10context')\n",
    "clean_train_reviews = []\n",
    "for review in train['review']:\n",
    "    clean_train_reviews.append(review_wordlist(review, remove_stopwords=True))\n",
    "trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 22000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-cfa758f63ad4>:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec,model[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 22000\n",
      "Review 2000 of 22000\n",
      "Review 3000 of 22000\n",
      "Review 4000 of 22000\n",
      "Review 5000 of 22000\n",
      "Review 6000 of 22000\n",
      "Review 7000 of 22000\n",
      "Review 8000 of 22000\n",
      "Review 9000 of 22000\n",
      "Review 10000 of 22000\n",
      "Review 11000 of 22000\n",
      "Review 12000 of 22000\n",
      "Review 13000 of 22000\n",
      "Review 14000 of 22000\n",
      "Review 15000 of 22000\n",
      "Review 16000 of 22000\n",
      "Review 17000 of 22000\n",
      "Review 18000 of 22000\n",
      "Review 19000 of 22000\n",
      "Review 20000 of 22000\n",
      "Review 21000 of 22000\n"
     ]
    }
   ],
   "source": [
    "test_reviews = []\n",
    "test_reviews.append(review_wordlist(text,remove_stopwords=True))\n",
    "testDataVecs = getAvgFeatureVecs(test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting random forest to training data....\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "print(\"Fitting random forest to training data....\")    \n",
    "forest = forest.fit(trainDataVecs, train[\"sentiment\"])\n",
    "#result = forest.predict(testDataVecs)\n",
    "\n",
    "with open('model.pickle','wb') as f:\n",
    "    pickle.dump(forest,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
